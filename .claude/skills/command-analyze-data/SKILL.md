---
name: analyze-data
description: "데이터 분석 스킬. 데이터셋 탐색, 통계 분석, 시각화, 인사이트 도출을 수행합니다."
---

# Analyze Data

데이터를 분석하여 통계적 요약 및 인사이트 리포트를 작성하는 스킬입니다.

## 목적

- 데이터셋의 특성과 구조를 파악
- 탐색적 데이터 분석(EDA) 수행
- 통계적 요약 및 분포 분석
- 데이터 품질 검사 (결측치, 이상치)
- 인사이트 도출 및 권장사항 제시
- 분석 결과를 구조화된 리포트로 문서화

## 핵심 원칙

1. **데이터 이해 우선**: 분석 전 데이터 구조와 맥락 파악
2. **객관적 분석**: 데이터에 기반한 객관적 해석
3. **품질 검증**: 결측치, 이상치, 데이터 타입 검사 필수
4. **시각화 활용**: 패턴과 분포를 시각적으로 표현
5. **실행 가능한 인사이트**: 구체적인 권장사항 도출

## 키워드

분석 유형 판단에 사용되는 키워드:
- 데이터 분석, 통계, 데이터셋, EDA, 시각화, 인사이트
- data analysis, statistics, dataset, metrics
- 분포, 상관관계, 기술통계, 탐색적 분석

## 워크플로우

```
데이터 소스 확인 → 데이터 로드 → 기본 정보 파악 → EDA → 통계 요약
                                                      ↓
              인사이트 도출 ← 시각화 ← 품질 검사
                    ↓
              분석 리포트 작성
```

### 1단계: 데이터 소스 확인

지원하는 데이터 소스 유형을 확인합니다.

**지원 형식:**
| 형식 | 확장자 | 설명 |
|------|--------|------|
| CSV | .csv | 쉼표 구분 값 |
| JSON | .json | JSON 데이터 |
| Excel | .xlsx, .xls | 엑셀 스프레드시트 |
| Parquet | .parquet | 열 기반 저장 형식 |
| SQLite | .db, .sqlite | SQLite 데이터베이스 |
| API | - | REST API 응답 데이터 |

**확인 항목:**
- 데이터 파일 경로 또는 소스
- 데이터 형식 및 인코딩
- 데이터 크기 (행/열 수 추정)

### 2단계: 데이터 로드 및 기본 정보 파악

데이터를 로드하고 기본 구조를 파악합니다.

**확인 항목:**
- 행/열 수
- 컬럼명 및 데이터 타입
- 메모리 사용량
- 샘플 데이터 (상위 5-10행)

**예시 출력:**
```
데이터셋 개요:
- 행 수: 10,000
- 열 수: 15
- 메모리: 1.2 MB

컬럼 정보:
| 컬럼명 | 데이터 타입 | 예시 값 |
|--------|------------|---------|
| id | int64 | 1, 2, 3 |
| name | object | "Alice", "Bob" |
| age | float64 | 25.0, 30.5 |
```

### 3단계: 탐색적 데이터 분석 (EDA)

데이터의 특성을 탐색합니다.

**분석 항목:**
1. **수치형 변수**: 범위, 분포, 중심 경향
2. **범주형 변수**: 고유값 개수, 빈도 분포
3. **시간형 변수**: 기간, 트렌드, 계절성
4. **변수 간 관계**: 상관관계, 패턴

### 4단계: 통계 요약

기술 통계량을 계산합니다.

**수치형 변수 통계:**
| 통계량 | 설명 |
|--------|------|
| count | 유효 데이터 수 |
| mean | 평균 |
| std | 표준편차 |
| min | 최솟값 |
| 25% | 1사분위수 |
| 50% | 중앙값 |
| 75% | 3사분위수 |
| max | 최댓값 |

**범주형 변수 통계:**
| 통계량 | 설명 |
|--------|------|
| count | 전체 데이터 수 |
| unique | 고유값 개수 |
| top | 최빈값 |
| freq | 최빈값 빈도 |

### 5단계: 데이터 품질 검사

데이터 품질 이슈를 식별합니다.

**검사 항목:**

| 항목 | 설명 | 임계값 |
|------|------|--------|
| 결측치 | NULL/NaN 비율 | > 5% 경고 |
| 중복 행 | 동일한 행 존재 | > 1% 경고 |
| 이상치 | IQR 기준 이상치 | > 2% 경고 |
| 데이터 타입 | 불일치 타입 | 즉시 보고 |
| 일관성 | 형식 불일치 | 즉시 보고 |

**이상치 탐지 방법:**
- IQR 방식: Q1 - 1.5*IQR ~ Q3 + 1.5*IQR 범위 외
- Z-score: |z| > 3 기준
- 도메인 규칙: 비즈니스 로직 기반

### 6단계: 시각화 (필요시)

데이터 패턴을 시각적으로 표현합니다.

**권장 시각화:**

| 데이터 유형 | 권장 차트 |
|------------|----------|
| 분포 | 히스토그램, 박스플롯 |
| 범주형 비교 | 막대 차트 |
| 시계열 | 라인 차트 |
| 상관관계 | 히트맵, 산점도 |
| 비율 | 파이 차트 |

**시각화 설명 템플릿:**
```
[차트 유형]: [변수명]
- 패턴: [관찰된 패턴]
- 특이사항: [이상치, 클러스터 등]
- 해석: [의미]
```

### 7단계: 인사이트 및 권장사항 도출

분석 결과를 기반으로 인사이트를 도출합니다.

**인사이트 구조:**
1. **주요 발견사항**: 데이터에서 발견한 핵심 패턴
2. **데이터 품질 이슈**: 해결이 필요한 품질 문제
3. **비즈니스 시사점**: 의사결정에 활용 가능한 정보
4. **권장사항**: 구체적인 후속 조치

**권장사항 유형:**
| 유형 | 예시 |
|------|------|
| 데이터 정제 | "결측치가 많은 컬럼 X 처리 필요" |
| 추가 분석 | "변수 A와 B의 상관관계 심층 분석 권장" |
| 모델링 제안 | "시계열 예측 모델 적용 가능" |
| 비즈니스 액션 | "이상치 그룹에 대한 별도 전략 필요" |

### 8단계: 분석 리포트 작성

분석 결과를 문서로 저장합니다.

**저장 위치:**
```
.workflow/analyze/<YYYYMMDD>-<HHMMSS>-<제목>/report.md
```

## 문서 템플릿

```markdown
# [데이터셋명] 데이터 분석 리포트

- 분석 일시: YYYY-MM-DD HH:MM:SS (KST)
- 데이터 소스: [소스 경로 또는 설명]
- 분석 유형: 데이터 분석 (analyze-data)

## 요약

[1-2문장으로 핵심 발견사항 요약]

## 데이터셋 개요

### 기본 정보
- 행 수: N
- 열 수: M
- 데이터 형식: [CSV/JSON/등]
- 기간: [해당시]

### 컬럼 정보

| 컬럼명 | 데이터 타입 | 설명 | 결측률 |
|--------|------------|------|--------|
| col1 | int64 | 설명 | 0% |
| col2 | object | 설명 | 5% |

## 탐색적 데이터 분석 (EDA)

### 수치형 변수 분석

#### [변수명]
- 분포: [정규/우편향/좌편향/등]
- 범위: [min] ~ [max]
- 중심: 평균 [mean], 중앙값 [median]
- 특이사항: [이상치, 클러스터 등]

### 범주형 변수 분석

#### [변수명]
- 고유값 수: N
- 최빈값: [value] (N%)
- 분포: [균등/불균등/등]

### 변수 간 관계

#### 상관관계
| 변수 쌍 | 상관계수 | 해석 |
|---------|---------|------|
| A - B | 0.85 | 강한 양의 상관 |

## 데이터 품질

### 결측치 현황

| 컬럼 | 결측 수 | 비율 | 처리 권장 |
|------|--------|------|----------|
| col1 | 100 | 1% | 허용 가능 |
| col2 | 500 | 5% | 처리 필요 |

### 이상치 현황

| 컬럼 | 이상치 수 | 비율 | 특성 |
|------|----------|------|------|
| col1 | 50 | 0.5% | 상한 초과 |

### 품질 점수
- 전체 품질 점수: [상/중/하]
- 주요 이슈: [요약]

## 인사이트

### 주요 발견사항
1. [발견사항 1]
2. [발견사항 2]
3. [발견사항 3]

### 비즈니스 시사점
- [시사점 1]
- [시사점 2]

## 권장사항

### 데이터 품질 개선
1. [권장사항 1]
2. [권장사항 2]

### 추가 분석 제안
1. [분석 제안 1]
2. [분석 제안 2]

### 활용 방안
1. [활용 방안 1]
2. [활용 방안 2]

## 부록

### 통계 요약표

[상세 기술통계 테이블]

### 시각화 목록

[생성된 시각화 파일 경로 또는 설명]
```

## 결과 보고 형식

분석 완료 후 다음 형식으로 결과를 보고합니다:

```markdown
## 데이터 분석 완료

### 분석 문서
- **경로**: `.workflow/analyze/<YYYYMMDD>-<HHMMSS>-<제목>/report.md`
- **작성 일시**: YYYY-MM-DD HH:MM:SS (KST)
- **분석 유형**: 데이터 분석 (analyze-data)

### 데이터셋 요약
- **데이터 소스**: [소스]
- **행/열**: N행 x M열
- **데이터 품질**: [상/중/하]

### 주요 발견사항
1. [발견사항 1]
2. [발견사항 2]
3. [발견사항 3]

### 권장사항
- [권장사항 요약]

### 다음 단계
- 데이터 정제: [필요시]
- 추가 분석: [필요시]
- 모델링: [필요시]
```

## 도구 활용

### 데이터 읽기
- Read 도구: CSV, JSON 파일 직접 읽기
- Bash 도구: Python/pandas 스크립트 실행

### 분석 수행
```python
# 예시: pandas 기본 분석
import pandas as pd

df = pd.read_csv('data.csv')
print(df.info())
print(df.describe())
print(df.isnull().sum())
```

### 시각화 생성
```python
# 예시: matplotlib 시각화
import matplotlib.pyplot as plt

df['column'].hist()
plt.savefig('histogram.png')
```

## 주의사항

1. **대용량 데이터**: 샘플링을 통한 분석 권장 (> 100만 행)
2. **민감 데이터**: PII(개인식별정보) 포함 여부 확인
3. **데이터 보존**: 원본 데이터 수정 금지
4. **재현성**: 분석 과정 문서화
5. **해석 주의**: 상관관계 != 인과관계
6. **컨텍스트 고려**: 도메인 지식 반영
